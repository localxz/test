import collections.abc as container_abcs
import math
from itertools import repeat

import numpy as np
import torch
from torch import nn
from torch._jit_internal import Optional
from torch.nn import functional as F
from torch.nn import init
from torch.nn.modules.module import Module
from torch.nn.parameter import Parameter
from torchvision.transforms.functional import rgb_to_grayscale

from models.laplace import EA, make_laplace_pyramid

__all__ = ["DOConv2d"]


class DOConv2d(Module):
    # ... (rest of DOConv2d class is unchanged) ...
    __constants__ = [
        "stride",
        "padding",
        "dilation",
        "groups",
        "padding_mode",
        "output_padding",
        "in_channels",
        "out_channels",
        "kernel_size",
        "D_mul",
    ]
    __annotations__ = {"bias": Optional[torch.Tensor]}

    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        D_mul=None,
        stride=1,
        padding=0,
        dilation=1,
        groups=1,
        bias=True,
        padding_mode="zeros",
    ):
        super(DOConv2d, self).__init__()

        kernel_size = _pair(kernel_size)
        stride = _pair(stride)
        padding = _pair(padding)
        dilation = _pair(dilation)

        if in_channels % groups != 0:
            raise ValueError("in_channels must be divisible by groups")
        if out_channels % groups != 0:
            raise ValueError("out_channels must be divisible by groups")
        valid_padding_modes = {"zeros", "reflect", "replicate", "circular"}
        if padding_mode not in valid_padding_modes:
            raise ValueError(
                "padding_mode must be one of {}, but got padding_mode='{}'".format(
                    valid_padding_modes, padding_mode
                )
            )
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.groups = groups
        self.padding_mode = padding_mode
        self._padding_repeated_twice = tuple(x for x in self.padding for _ in range(2))

        #################################### Initailization of D & W ###################################
        M = self.kernel_size[0]
        N = self.kernel_size[1]
        self.D_mul = M * N if D_mul is None or M * N <= 1 else D_mul
        self.W = Parameter(
            torch.Tensor(out_channels, in_channels // groups, self.D_mul)
        )
        init.kaiming_uniform_(self.W, a=math.sqrt(5))

        if M * N > 1:
            self.D = Parameter(torch.Tensor(in_channels, M * N, self.D_mul))
            init_zero = np.zeros([in_channels, M * N, self.D_mul], dtype=np.float32)
            self.D.data = torch.from_numpy(init_zero)

            eye = torch.reshape(
                torch.eye(M * N, dtype=torch.float32), (1, M * N, M * N)
            )
            d_diag = eye.repeat((in_channels, 1, self.D_mul // (M * N)))
            if self.D_mul % (M * N) != 0:  # the cases when D_mul > M * N
                zeros = torch.zeros([in_channels, M * N, self.D_mul % (M * N)])
                self.d_diag = Parameter(
                    torch.cat([d_diag, zeros], dim=2), requires_grad=False
                )
            else:  # the case when D_mul = M * N
                self.d_diag = Parameter(d_diag, requires_grad=False)
        ##################################################################################################

        if bias:
            self.bias = Parameter(torch.Tensor(out_channels))
            fan_in, _ = init._calculate_fan_in_and_fan_out(self.W)
            bound = 1 / math.sqrt(fan_in)
            init.uniform_(self.bias, -bound, bound)
        else:
            self.register_parameter("bias", None)

    def extra_repr(self):
        s = "{in_channels}, {out_channels}, kernel_size={kernel_size}, stride={stride}"
        if self.padding != (0,) * len(self.padding):
            s += ", padding={padding}"
        if self.dilation != (1,) * len(self.dilation):
            s += ", dilation={dilation}"
        if self.groups != 1:
            s += ", groups={groups}"
        if self.bias is None:
            s += ", bias=False"
        if self.padding_mode != "zeros":
            s += ", padding_mode={padding_mode}"
        return s.format(**self.__dict__)

    def __setstate__(self, state):
        super(DOConv2d, self).__setstate__(state)
        if not hasattr(self, "padding_mode"):
            self.padding_mode = "zeros"

    def _conv_forward(self, input, weight):
        if self.padding_mode != "zeros":
            return F.conv2d(
                F.pad(input, self._padding_repeated_twice, mode=self.padding_mode),
                weight,
                self.bias,
                self.stride,
                _pair(0),
                self.dilation,
                self.groups,
            )
        return F.conv2d(
            input,
            weight,
            self.bias,
            self.stride,
            self.padding,
            self.dilation,
            self.groups,
        )

    def forward(self, input):
        M = self.kernel_size[0]
        N = self.kernel_size[1]
        DoW_shape = (self.out_channels, self.in_channels // self.groups, M, N)
        if M * N > 1:
            D = self.D + self.d_diag
            W = torch.reshape(
                self.W, (self.out_channels // self.groups, self.in_channels, self.D_mul)
            )
            DoW = torch.reshape(torch.einsum("ims,ois->oim", D, W), DoW_shape)
        else:
            DoW = torch.reshape(self.W, DoW_shape)
        return self._conv_forward(input, DoW)


def _ntuple(n):
    def parse(x):
        if isinstance(x, container_abcs.Iterable):
            return x
        return tuple(repeat(x, n))

    return parse


_pair = _ntuple(2)


class DFIM(nn.Module):
    def __init__(self, planes_high, planes_low, planes_out):
        super(DFIM, self).__init__()
        # This block does not use pooling, so BatchNorm is fine.
        self.pa = nn.Sequential(
            DOConv2d(planes_low, planes_low // 4, kernel_size=1),
            nn.BatchNorm2d(planes_low // 4),
            nn.ReLU(True),
            DOConv2d(planes_low // 4, planes_low, kernel_size=1),
            nn.BatchNorm2d(planes_low),
            nn.Sigmoid(),
        )
        # This block does not use pooling, so BatchNorm is fine.
        self.plus_conv = nn.Sequential(
            DOConv2d(planes_high, planes_low, kernel_size=1),
            nn.BatchNorm2d(planes_low),
            nn.ReLU(True),
        )

        # --- Start of The Correct Fix ---
        # This 'ca' block pools to 1x1, so the normalization layers after it are invalid.
        # They have been removed.
        self.ca = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            DOConv2d(planes_low, planes_low // 4, kernel_size=1),
            nn.ReLU(True),  # The invalid BatchNorm2d was here
            DOConv2d(planes_low // 4, planes_low, kernel_size=1),
            nn.Sigmoid(),  # The invalid BatchNorm2d was here
        )
        # --- End of The Correct Fix ---

        # This block does not use pooling, so BatchNorm is fine.
        self.end_conv = nn.Sequential(
            DOConv2d(planes_low, planes_out, 3, stride=1, padding=1),
            nn.BatchNorm2d(planes_out),
            nn.ReLU(True),
        )

    def forward(self, x_high, x_low):
        x_high = self.plus_conv(x_high)
        pa = self.pa(x_low)
        ca = self.ca(x_high)

        feat = x_low + x_high
        feat = self.end_conv(feat)
        feat = feat * ca
        feat = feat * pa
        return feat


class BasicConv(nn.Module):
    # ... (rest of BasicConv class is unchanged) ...
    def __init__(
        self,
        in_planes,
        out_planes,
        kernel_size,
        stride=1,
        padding=0,
        dilation=1,
        groups=1,
        relu=True,
        bn=True,
    ):
        super(BasicConv, self).__init__()
        self.out_channels = out_planes
        if bn:
            self.conv = DOConv2d(
                in_planes,
                out_planes,
                kernel_size=kernel_size,
                stride=stride,
                padding=padding,
                dilation=dilation,
                groups=groups,
                bias=False,
            )
            self.bn = nn.InstanceNorm2d(
                out_planes, eps=1e-5, momentum=0.01, affine=True
            )
            self.relu = nn.ReLU(inplace=True) if relu else None
        else:
            self.conv = DOConv2d(
                in_planes,
                out_planes,
                kernel_size=kernel_size,
                stride=stride,
                padding=padding,
                dilation=dilation,
                groups=groups,
                bias=True,
            )
            self.bn = None
            self.relu = nn.ReLU(inplace=True) if relu else None

    def forward(self, x):
        x = self.conv(x)
        if self.bn is not None:
            x = self.bn(x)
        if self.relu is not None:
            x = self.relu(x)
        return x


class MDPM(nn.Module):
    # ... (rest of MDPM class is unchanged) ...
    def __init__(
        self,
        in_planes,
        out_planes,
        stride=1,
        scale=0.1,
        map_reduce=8,
        vision=1,
        groups=1,
    ):
        super(MDPM, self).__init__()
        self.scale = scale
        self.out_channels = out_planes
        inter_planes = in_planes // map_reduce

        self.branch0 = nn.Sequential(
            BasicConv(
                in_planes,
                inter_planes,
                kernel_size=1,
                stride=1,
                groups=groups,
                relu=False,
            ),
            BasicConv(
                inter_planes,
                2 * inter_planes,
                kernel_size=(3, 3),
                stride=stride,
                padding=(1, 1),
                groups=groups,
            ),
            BasicConv(
                2 * inter_planes,
                2 * inter_planes,
                kernel_size=3,
                stride=1,
                padding=vision + 1,
                dilation=vision + 1,
                relu=False,
                groups=groups,
            ),
        )
        self.branch1 = nn.Sequential(
            BasicConv(
                in_planes,
                inter_planes,
                kernel_size=1,
                stride=1,
                groups=groups,
                relu=False,
            ),
            BasicConv(
                inter_planes,
                2 * inter_planes,
                kernel_size=(3, 3),
                stride=stride,
                padding=(1, 1),
                groups=groups,
            ),
            BasicConv(
                2 * inter_planes,
                2 * inter_planes,
                kernel_size=3,
                stride=1,
                padding=vision + 2,
                dilation=vision + 2,
                relu=False,
                groups=groups,
            ),
        )
        self.branch2 = nn.Sequential(
            BasicConv(
                in_planes,
                inter_planes,
                kernel_size=1,
                stride=1,
                groups=groups,
                relu=False,
            ),
            BasicConv(
                inter_planes,
                (inter_planes // 2) * 3,
                kernel_size=3,
                stride=1,
                padding=1,
                groups=groups,
            ),
            BasicConv(
                (inter_planes // 2) * 3,
                2 * inter_planes,
                kernel_size=3,
                stride=stride,
                padding=1,
                groups=groups,
            ),
            BasicConv(
                2 * inter_planes,
                2 * inter_planes,
                kernel_size=3,
                stride=1,
                padding=vision + 4,
                dilation=vision + 4,
                relu=False,
                groups=groups,
            ),
        )

        self.ConvLinear = BasicConv(
            6 * inter_planes, out_planes, kernel_size=1, stride=1, relu=False
        )
        self.shortcut = BasicConv(
            in_planes, out_planes, kernel_size=1, stride=stride, relu=False
        )
        self.relu = nn.ReLU(inplace=False)
        self.EA = EA(in_planes)

    def forward(self, x, edge):
        x, am = self.EA(x, edge)
        short = self.shortcut(x)
        out = self.relu(short)
        return out, am


if __name__ == "__main__":
    x1 = torch.rand(8, 3, 256, 256)
    x2 = torch.rand(8, 32, 64, 64)
    mdpm_1 = MDPM(32, 32)
    grayscale_img_x = rgb_to_grayscale(x1)
    edge_feature_x = make_laplace_pyramid(grayscale_img_x, 5, 1)
    edge_feature_x = edge_feature_x[2]
    x2, am_x1 = mdpm_1(x2, edge_feature_x)
    print("x2:", x2.shape)
    print("edge:", edge_feature_x.shape)
